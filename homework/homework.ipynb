{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad0bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75137781",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '../files/input/test_data.csv.zip'\n",
    "train_path = '../files/input/train_data.csv.zip'\n",
    "categorical_cols = ['SEX', 'EDUCATION', 'MARRIAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea739945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1.\n",
    "# Realice la limpieza de los datasets:\n",
    "# - Renombre la columna \"default payment next month\" a \"default\".\n",
    "# - Remueva la columna \"ID\".\n",
    "# - Elimine los registros con informacion no disponible.\n",
    "# - Para la columna EDUCATION, valores > 4 indican niveles superiores\n",
    "#   de educación, agrupe estos valores en la categoría \"others\".\n",
    "# - Renombre la columna \"default payment next month\" a \"default\"\n",
    "# - Remueva la columna \"ID\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d548e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Renombrar la columna \"default payment next month\" a \"default\"\n",
    "    df = df.rename(columns={\"default payment next month\": \"default\"})\n",
    "    \n",
    "    # Remover la columna \"ID\"\n",
    "    if 'ID' in df.columns:\n",
    "        df = df.drop(columns=['ID'])\n",
    "    \n",
    "    # Eliminar registros con información no disponible\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Agrupar valores > 4 en EDUCATION como 4 (others)\n",
    "    if 'EDUCATION' in df.columns:\n",
    "        df['EDUCATION'] = df['EDUCATION'].astype(int)\n",
    "        df.loc[df['EDUCATION'] > 4, 'EDUCATION'] = 4\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767a175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 2.\n",
    "# Divida los datasets en x_train, y_train, x_test, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac66932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_data(test_path: str, train_path: str):\n",
    "    import pandas as pd\n",
    "\n",
    "    df_test = pd.read_csv(test_path,\n",
    "            index_col=False,\n",
    "            compression='zip',\n",
    "            )\n",
    "    \n",
    "    df_train = pd.read_csv(train_path,\n",
    "            index_col=False,\n",
    "            compression='zip',\n",
    "            )\n",
    "\n",
    "    # Aplicar limpieza a ambos DataFrames\n",
    "    df_test = clean_data(df_test)\n",
    "    df_train = clean_data(df_train)\n",
    "\n",
    "# Ahora separar X/y con el nombre ya renombrado (\"default\")\n",
    "    target_col = 'default'\n",
    "    data_test = df_test.drop(columns=[target_col])\n",
    "    target_test = df_test[target_col].astype(int)\n",
    "    data_train = df_train.drop(columns=[target_col])\n",
    "    target_train = df_train[target_col].astype(int)\n",
    "\n",
    "    \n",
    "    return data_train, target_train, data_test, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e5c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3.\n",
    "# Cree un pipeline para el modelo de clasificación. Este pipeline debe\n",
    "# contener las siguientes capas:\n",
    "# - Transforma las variables categoricas usando el método\n",
    "#   one-hot-encoding.\n",
    "# - Ajusta un modelo de bosques aleatorios (rando forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "544ce798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(estimator):\n",
    "\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "\n",
    "    transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "        ],\n",
    "        remainder='passthrough'  # mantiene las columnas numéricas sin cambios\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', transformer),\n",
    "            ('classifier', estimator)\n",
    "        ],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28cd6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4.\n",
    "# Optimice los hiperparametros del pipeline usando validación cruzada.\n",
    "# Use 10 splits para la validación cruzada. Use la función de precision\n",
    "# balanceada para medir la precisión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0402ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid_search(estimator, param_grid, cv=10, scoring='balanced_accuracy', n_jobs=None):\n",
    "\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    return grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f711ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5.\n",
    "# Guarde el modelo (comprimido con gzip) como \"files/models/model.pkl.gz\".\n",
    "# Recuerde que es posible guardar el modelo comprimido usanzo la libreria gzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e973d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_estimator(estimator):\n",
    "\n",
    "    import gzip\n",
    "    import pickle\n",
    "    import os\n",
    "\n",
    "    model_dir = '../files/models'\n",
    "\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir, 'model.pkl.gz')\n",
    "\n",
    "    with gzip.open(model_path, 'wb') as file:\n",
    "        pickle.dump(estimator, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74b0a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_estimator():\n",
    "\n",
    "    import os\n",
    "    import gzip\n",
    "    import pickle\n",
    "\n",
    "    model_dir = '../files/models'\n",
    "    model_path = os.path.join(model_dir, 'model.pkl.gz')\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        return None\n",
    "    with gzip.open(model_path, 'rb') as file:\n",
    "        estimator = pickle.load(file)\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a37c3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 6.\n",
    "# Calcule las metricas de precision, precision balanceada, recall,\n",
    "# y f1-score para los conjuntos de entrenamiento y prueba.\n",
    "# Guardelas en el archivo files/output/metrics.json. Cada fila\n",
    "# del archivo es un diccionario con las metricas de un modelo.\n",
    "# Este diccionario tiene un campo para indicar si es el conjunto\n",
    "# de entrenamiento o prueba. Por ejemplo:\n",
    "#\n",
    "# {'dataset': 'train', 'precision': 0.8, 'balanced_accuracy': 0.7, 'recall': 0.9, 'f1_score': 0.85}\n",
    "# {'dataset': 'test', 'precision': 0.7, 'balanced_accuracy': 0.6, 'recall': 0.8, 'f1_score': 0.75}\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f3d3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_estimator(estimator):\n",
    "\n",
    "    from sklearn.metrics import balanced_accuracy_score, precision_score\n",
    "\n",
    "    x_train, y_train, x_test, y_test = load_clean_data(test_path, train_path)\n",
    "\n",
    "\n",
    "    estimator.fit(x_train, y_train)\n",
    "    best_estimator = load_estimator()\n",
    "\n",
    "\n",
    "    if best_estimator is not None:\n",
    "\n",
    "        saved_bas = balanced_accuracy_score(\n",
    "        y_true=y_test, y_pred=best_estimator.predict(x_test)\n",
    "        )\n",
    "\n",
    "        current_bas = balanced_accuracy_score(\n",
    "            y_true=y_test, y_pred=estimator.predict(x_test)\n",
    "        )\n",
    "\n",
    "        if saved_bas > current_bas:\n",
    "            estimator = best_estimator\n",
    "\n",
    "        elif saved_bas > 0.90*current_bas and saved_bas > 0.673:\n",
    "\n",
    "            saved_ps = precision_score(\n",
    "                y_true=y_test, y_pred=best_estimator.predict(x_test)\n",
    "            )\n",
    "\n",
    "            current_ps = precision_score(\n",
    "                y_true=y_test, y_pred=estimator.predict(x_test)\n",
    "            )\n",
    "\n",
    "            if saved_ps >= current_ps:\n",
    "                estimator = best_estimator\n",
    "\n",
    "\n",
    "    save_estimator(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3699dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf_estimator():\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    pipeline = make_pipeline(RandomForestClassifier(random_state=42))\n",
    "    param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "    estimator = make_grid_search(\n",
    "        estimator=pipeline, \n",
    "        param_grid=param_grid, \n",
    "        cv=10, \n",
    "        scoring='balanced_accuracy',\n",
    "        n_jobs=-1\n",
    "        )\n",
    "   \n",
    "    train_estimator(estimator)\n",
    "\n",
    "train_rf_estimator()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "470dd1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(estimator, x_train, y_train, x_test, y_test):\n",
    "\n",
    "    from sklearn.metrics import (\n",
    "        precision_score,\n",
    "        balanced_accuracy_score,\n",
    "        recall_score,\n",
    "        f1_score,\n",
    "        confusion_matrix,\n",
    "    )\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_train = estimator.predict(x_train)\n",
    "    y_pred_test  = estimator.predict(x_test)\n",
    "\n",
    "    # Helpers locales\n",
    "    \n",
    "    def metrics_dict(y_true, y_pred, dataset):\n",
    "        return {\n",
    "            \"type\": \"metrics\",\n",
    "            \"dataset\": dataset,\n",
    "            \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "            \"balanced_accuracy\": float(balanced_accuracy_score(y_true, y_pred)),\n",
    "            \"recall\": float(recall_score(y_true, y_pred, zero_division=0)),\n",
    "            \"f1_score\": float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "        }\n",
    "\n",
    "    def cm_dict(y_true, y_pred, dataset):\n",
    "        cm = confusion_matrix(y_true.astype(int), y_pred.astype(int), labels=[0, 1])\n",
    "        tn, fp, fn, tp = int(cm[0, 0]), int(cm[0, 1]), int(cm[1, 0]), int(cm[1, 1])\n",
    "        return {\n",
    "            \"type\": \"cm_matrix\",\n",
    "            \"dataset\": dataset,\n",
    "            \"true_0\": {\"predicted_0\": tn, \"predicted_1\": fp},\n",
    "            \"true_1\": {\"predicted_0\": fn, \"predicted_1\": tp},\n",
    "        }\n",
    "\n",
    "    # Construye los 4 renglones en el orden exacto que pide el test\n",
    "    metrics_train = metrics_dict(y_train, y_pred_train, \"train\")\n",
    "    metrics_test  = metrics_dict(y_test,  y_pred_test,  \"test\")\n",
    "    cm_train      = cm_dict(y_train, y_pred_train, \"train\")\n",
    "    cm_test       = cm_dict(y_test,  y_pred_test,  \"test\")\n",
    "\n",
    "    return metrics_train, metrics_test, cm_train, cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee283cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_report(\n",
    "   metrics_train,\n",
    "   metrics_test,\n",
    "   cm_train,\n",
    "   cm_test,\n",
    "):\n",
    "    \n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    path = '../files/output/metrics.json'\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "       os.makedirs(os.path.dirname(path))\n",
    "\n",
    "    with open(path, 'w', encoding='utf-8', newline='\\n') as f:\n",
    "       f.write(json.dumps(metrics_train) + '\\n')\n",
    "       f.write(json.dumps(metrics_test) + '\\n')\n",
    "       f.write(json.dumps(cm_train) + '\\n')\n",
    "       f.write(json.dumps(cm_test) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1bf2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(metrics_train, metrics_test, cm_train=None, cm_test=None):\n",
    "    \"\"\"Imprime un resumen compacto de métricas.\n",
    "    Muestra valores de test con el valor de train entre paréntesis.\n",
    "    \"\"\"\n",
    "    def fmt(name, test_val, train_val):\n",
    "        return f\"{name:>20}: {test_val:.4f} ({train_val:.4f})\"\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Metrics summary (test (train))\")\n",
    "    print(\"-\" * 80)\n",
    "    print(fmt(\"Balanced Accuracy\", metrics_test[\"balanced_accuracy\"], metrics_train[\"balanced_accuracy\"]))\n",
    "    print(fmt(\"Precision\",         metrics_test[\"precision\"],         metrics_train[\"precision\"]))\n",
    "    print(fmt(\"Recall\",            metrics_test[\"recall\"],            metrics_train[\"recall\"]))\n",
    "    print(fmt(\"F1-score\",          metrics_test[\"f1_score\"],          metrics_train[\"f1_score\"]))\n",
    "    if cm_test and cm_train:\n",
    "        print(\"-\" * 80)\n",
    "        print(\"Confusion matrix (test):\")\n",
    "        print(f\" true_0 -> predicted_0: {cm_test['true_0']['predicted_0']}, predicted_1: {cm_test['true_0']['predicted_1']}\")\n",
    "        print(f\" true_1 -> predicted_0: {cm_test['true_1']['predicted_0']}, predicted_1: {cm_test['true_1']['predicted_1']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7547d033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Metrics summary (test (train))\n",
      "--------------------------------------------------------------------------------\n",
      "   Balanced Accuracy: 0.6745 (0.8986)\n",
      "           Precision: 0.6681 (0.9932)\n",
      "              Recall: 0.4028 (0.7988)\n",
      "            F1-score: 0.5026 (0.8854)\n",
      "--------------------------------------------------------------------------------\n",
      "Confusion matrix (test):\n",
      " true_0 -> predicted_0: 6709, predicted_1: 382\n",
      " true_1 -> predicted_0: 1140, predicted_1: 769\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def check_estimator():\n",
    "\n",
    "    x_train, y_train, x_test, y_test = load_clean_data(test_path, train_path)\n",
    "\n",
    "    estimator = load_estimator()\n",
    "\n",
    "    metrics_train, metrics_test, cm_train, cm_test = eval_metrics(\n",
    "    estimator,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    )\n",
    "    save_report(\n",
    "        metrics_train,\n",
    "        metrics_test,\n",
    "        cm_train,\n",
    "        cm_test,\n",
    "    )\n",
    "    print_report(             \n",
    "        metrics_train,\n",
    "        metrics_test,\n",
    "        cm_train,\n",
    "        cm_test,\n",
    "    )\n",
    "\n",
    "check_estimator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90b26b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('cat',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['SEX', 'EDUCATION',\n",
      "                                                   'MARRIAGE'])])),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(min_samples_leaf=2, min_samples_split=5,\n",
      "                                        n_estimators=200, random_state=42))])\n",
      "_______________________________\n",
      "{'cv': 10, 'error_score': nan, 'estimator__memory': None, 'estimator__steps': [('preprocessor', ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('cat', OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['SEX', 'EDUCATION', 'MARRIAGE'])])), ('classifier', RandomForestClassifier(random_state=42))], 'estimator__transform_input': None, 'estimator__verbose': False, 'estimator__preprocessor': ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('cat', OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['SEX', 'EDUCATION', 'MARRIAGE'])]), 'estimator__classifier': RandomForestClassifier(random_state=42), 'estimator__preprocessor__force_int_remainder_cols': 'deprecated', 'estimator__preprocessor__n_jobs': None, 'estimator__preprocessor__remainder': 'passthrough', 'estimator__preprocessor__sparse_threshold': 0.3, 'estimator__preprocessor__transformer_weights': None, 'estimator__preprocessor__transformers': [('cat', OneHotEncoder(handle_unknown='ignore'), ['SEX', 'EDUCATION', 'MARRIAGE'])], 'estimator__preprocessor__verbose': False, 'estimator__preprocessor__verbose_feature_names_out': True, 'estimator__preprocessor__cat': OneHotEncoder(handle_unknown='ignore'), 'estimator__preprocessor__cat__categories': 'auto', 'estimator__preprocessor__cat__drop': None, 'estimator__preprocessor__cat__dtype': <class 'numpy.float64'>, 'estimator__preprocessor__cat__feature_name_combiner': 'concat', 'estimator__preprocessor__cat__handle_unknown': 'ignore', 'estimator__preprocessor__cat__max_categories': None, 'estimator__preprocessor__cat__min_frequency': None, 'estimator__preprocessor__cat__sparse_output': True, 'estimator__classifier__bootstrap': True, 'estimator__classifier__ccp_alpha': 0.0, 'estimator__classifier__class_weight': None, 'estimator__classifier__criterion': 'gini', 'estimator__classifier__max_depth': None, 'estimator__classifier__max_features': 'sqrt', 'estimator__classifier__max_leaf_nodes': None, 'estimator__classifier__max_samples': None, 'estimator__classifier__min_impurity_decrease': 0.0, 'estimator__classifier__min_samples_leaf': 1, 'estimator__classifier__min_samples_split': 2, 'estimator__classifier__min_weight_fraction_leaf': 0.0, 'estimator__classifier__monotonic_cst': None, 'estimator__classifier__n_estimators': 100, 'estimator__classifier__n_jobs': None, 'estimator__classifier__oob_score': False, 'estimator__classifier__random_state': 42, 'estimator__classifier__verbose': 0, 'estimator__classifier__warm_start': False, 'estimator': Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('cat',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['SEX', 'EDUCATION',\n",
      "                                                   'MARRIAGE'])])),\n",
      "                ('classifier', RandomForestClassifier(random_state=42))]), 'n_jobs': -1, 'param_grid': {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [None, 10, 20], 'classifier__min_samples_split': [2, 5], 'classifier__min_samples_leaf': [1, 2]}, 'pre_dispatch': '2*n_jobs', 'refit': True, 'return_train_score': False, 'scoring': 'balanced_accuracy', 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "best_params = load_estimator().best_estimator_\n",
    "print(best_params)\n",
    "print('_______________________________')\n",
    "print(load_estimator().get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2f3c1",
   "metadata": {},
   "source": [
    "def eval_metricts(\n",
    "    estimator,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test\n",
    "):\n",
    "    \n",
    "    from sklearn.metrics import precision_score, balanced_accuracy_score, recall_score, f1_score\n",
    "\n",
    "    y_pred_train = estimator.predict(x_train)\n",
    "    y_pred_test = estimator.predict(x_test)\n",
    "\n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    accuracy_train = balanced_accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = balanced_accuracy_score(y_test, y_pred_test)\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    f1_train = f1_score(y_train, y_pred_train)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "    \n",
    "    return (\n",
    "        precision_train,\n",
    "        precision_test,\n",
    "        accuracy_train,\n",
    "        accuracy_test,\n",
    "        recall_train,\n",
    "        recall_test,\n",
    "        f1_train,\n",
    "        f1_test\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
